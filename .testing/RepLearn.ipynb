{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed to the Apache Software Foundation (ASF) under one\n",
    "# or more contributor license agreements.  See the NOTICE file\n",
    "# distributed with this work for additional information\n",
    "# regarding copyright ownership.  The ASF licenses this file\n",
    "# to you under the Apache License, Version 2.0 (the\n",
    "# \"License\"); you may not use this file except in compliance\n",
    "# with the License.  You may obtain a copy of the License at\n",
    "\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an\n",
    "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "# KIND, either express or implied.  See the License for the\n",
    "# specific language governing permissions and limitations\n",
    "# under the License.\n",
    "\n",
    "\n",
    "# Implementation of causal CNNs partly taken and modified from\n",
    "# https://github.com/locuslab/TCN/blob/master/TCN/tcn.py, originally created\n",
    "# with the following license.\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2018 CMU Locus Lab\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class Chomp1d(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Removes the last elements of a time series.\n",
    "\n",
    "    Takes as input a three-dimensional tensor (`B`, `C`, `L`) where `B` is the\n",
    "    batch size, `C` is the number of input channels, and `L` is the length of\n",
    "    the input. Outputs a three-dimensional tensor (`B`, `C`, `L - s`) where `s`\n",
    "    is the number of elements to remove.\n",
    "\n",
    "    @param chomp_size Number of elements to remove.\n",
    "    \"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size]\n",
    "\n",
    "\n",
    "class SqueezeChannels(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Squeezes, in a three-dimensional tensor, the third dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SqueezeChannels, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.squeeze(2)\n",
    "\n",
    "\n",
    "class CausalConvolutionBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Causal convolution block, composed sequentially of two causal convolutions\n",
    "    (with leaky ReLU activation functions), and a parallel residual connection.\n",
    "\n",
    "    Takes as input a three-dimensional tensor (`B`, `C`, `L`) where `B` is the\n",
    "    batch size, `C` is the number of input channels, and `L` is the length of\n",
    "    the input. Outputs a three-dimensional tensor (`B`, `C`, `L`).\n",
    "\n",
    "    @param in_channels Number of input channels.\n",
    "    @param out_channels Number of output channels.\n",
    "    @param kernel_size Kernel size of the applied non-residual convolutions.\n",
    "    @param padding Zero-padding applied to the left of the input of the\n",
    "           non-residual convolutions.\n",
    "    @param final Disables, if True, the last activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation,\n",
    "                 final=False):\n",
    "        super(CausalConvolutionBlock, self).__init__()\n",
    "\n",
    "        # Computes left padding so that the applied convolutions are causal\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        # First causal convolution\n",
    "        conv1 = torch.nn.utils.weight_norm(torch.nn.Conv1d(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            padding=padding, dilation=dilation\n",
    "        ))\n",
    "        # The truncation makes the convolution causal\n",
    "        chomp1 = Chomp1d(padding)\n",
    "        relu1 = torch.nn.LeakyReLU()\n",
    "\n",
    "        # Second causal convolution\n",
    "        conv2 = torch.nn.utils.weight_norm(torch.nn.Conv1d(\n",
    "            out_channels, out_channels, kernel_size,\n",
    "            padding=padding, dilation=dilation\n",
    "        ))\n",
    "        chomp2 = Chomp1d(padding)\n",
    "        relu2 = torch.nn.LeakyReLU()\n",
    "\n",
    "        # Causal network\n",
    "        self.causal = torch.nn.Sequential(\n",
    "            conv1, chomp1, relu1, conv2, chomp2, relu2\n",
    "        )\n",
    "\n",
    "        # Residual connection\n",
    "        self.upordownsample = torch.nn.Conv1d(\n",
    "            in_channels, out_channels, 1\n",
    "        ) if in_channels != out_channels else None\n",
    "\n",
    "        # Final activation function\n",
    "        self.relu = torch.nn.LeakyReLU() if final else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_causal = self.causal(x)\n",
    "        res = x if self.upordownsample is None else self.upordownsample(x)\n",
    "        if self.relu is None:\n",
    "            return out_causal + res\n",
    "        else:\n",
    "            return self.relu(out_causal + res)\n",
    "\n",
    "\n",
    "class CausalCNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Causal CNN, composed of a sequence of causal convolution blocks.\n",
    "\n",
    "    Takes as input a three-dimensional tensor (`B`, `C`, `L`) where `B` is the\n",
    "    batch size, `C` is the number of input channels, and `L` is the length of\n",
    "    the input. Outputs a three-dimensional tensor (`B`, `C_out`, `L`).\n",
    "\n",
    "    @param in_channels Number of input channels.\n",
    "    @param channels Number of channels processed in the network and of output\n",
    "           channels.\n",
    "    @param depth Depth of the network.\n",
    "    @param out_channels Number of output channels.\n",
    "    @param kernel_size Kernel size of the applied non-residual convolutions.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, channels, depth, out_channels,\n",
    "                 kernel_size):\n",
    "        super(CausalCNN, self).__init__()\n",
    "\n",
    "        layers = []  # List of causal convolution blocks\n",
    "        dilation_size = 1  # Initial dilation size\n",
    "\n",
    "        for i in range(depth):\n",
    "            in_channels_block = in_channels if i == 0 else channels\n",
    "            layers += [CausalConvolutionBlock(\n",
    "                in_channels_block, channels, kernel_size, dilation_size\n",
    "            )]\n",
    "            dilation_size *= 2  # Doubles the dilation size at each step\n",
    "\n",
    "        # Last layer\n",
    "        layers += [CausalConvolutionBlock(\n",
    "            channels, out_channels, kernel_size, dilation_size\n",
    "        )]\n",
    "\n",
    "        self.network = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class CausalCNNEncoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder of a time series using a causal CNN: the computed representation is\n",
    "    the output of a fully connected layer applied to the output of an adaptive\n",
    "    max pooling layer applied on top of the causal CNN, which reduces the\n",
    "    length of the time series to a fixed size.\n",
    "\n",
    "    Takes as input a three-dimensional tensor (`B`, `C`, `L`) where `B` is the\n",
    "    batch size, `C` is the number of input channels, and `L` is the length of\n",
    "    the input. Outputs a three-dimensional tensor (`B`, `C`).\n",
    "\n",
    "    @param in_channels Number of input channels.\n",
    "    @param channels Number of channels manipulated in the causal CNN.\n",
    "    @param depth Depth of the causal CNN.\n",
    "    @param reduced_size Fixed length to which the output time series of the\n",
    "           causal CNN is reduced.\n",
    "    @param out_channels Number of output channels.\n",
    "    @param kernel_size Kernel size of the applied non-residual convolutions.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, channels, depth, reduced_size,\n",
    "                 out_channels, kernel_size):\n",
    "        super(CausalCNNEncoder, self).__init__()\n",
    "        causal_cnn = CausalCNN(\n",
    "            in_channels, channels, depth, reduced_size, kernel_size\n",
    "        )\n",
    "        reduce_size = torch.nn.AdaptiveMaxPool1d(1)\n",
    "        squeeze = SqueezeChannels()  # Squeezes the third dimension (time)\n",
    "        linear = torch.nn.Linear(reduced_size, out_channels)\n",
    "        self.network = torch.nn.Sequential(\n",
    "            causal_cnn, reduce_size, squeeze, linear\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbose/.conda/envs/appfl/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "cnn = CausalCNNEncoder(\n",
    "    5,\n",
    "    5,\n",
    "    10,\n",
    "    12,\n",
    "    3,\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand(32,5,100)\n",
    "cnn(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
